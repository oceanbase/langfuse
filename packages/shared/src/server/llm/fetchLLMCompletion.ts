// We need to use Zod3 for structured outputs due to a bug in
// ChatVertexAI. See issue: https://github.com/langfuse/langfuse/issues/7429
import { type ZodSchema } from "zod/v3";

import { ChatAnthropic } from "@langchain/anthropic";
import { ChatVertexAI } from "@langchain/google-vertexai";
import { ChatBedrockConverse } from "@langchain/aws";
import { ChatGoogleGenerativeAI } from "@langchain/google-genai";
import {
  AIMessage,
  BaseMessage,
  HumanMessage,
  SystemMessage,
  ToolMessage,
} from "@langchain/core/messages";
import {
  BytesOutputParser,
  StringOutputParser,
} from "@langchain/core/output_parsers";
import { IterableReadableStream } from "@langchain/core/utils/stream";
import { ChatOpenAI, AzureChatOpenAI } from "@langchain/openai";
import { env } from "../../env";
import GCPServiceAccountKeySchema, {
  BedrockConfigSchema,
  BedrockCredentialSchema,
  VertexAIConfigSchema,
  BEDROCK_USE_DEFAULT_CREDENTIALS,
} from "../../interfaces/customLLMProviderConfigSchemas";
import { processEventBatch } from "../ingestion/processEventBatch";
import { logger } from "../logger";
import {
  ChatMessage,
  ChatMessageRole,
  ChatMessageType,
  LLMAdapter,
  LLMJSONSchema,
  LLMToolDefinition,
  ModelParams,
  ToolCallResponse,
  ToolCallResponseSchema,
  TraceParams,
} from "./types";
import { CallbackHandler } from "langfuse-langchain";
import type { BaseCallbackHandler } from "@langchain/core/callbacks/base";
import { HttpsProxyAgent } from "https-proxy-agent";
import { clickhouseClient } from "../clickhouse/client";
import { eventTypes } from "../ingestion/types";

const isLangfuseCloud = Boolean(env.NEXT_PUBLIC_LANGFUSE_CLOUD_REGION);

type ProcessTracedEvents = () => Promise<void>;

type LLMCompletionParams = {
  messages: ChatMessage[];
  modelParams: ModelParams;
  structuredOutputSchema?: ZodSchema | LLMJSONSchema;
  callbacks?: BaseCallbackHandler[];
  baseURL?: string;
  apiKey: string;
  extraHeaders?: Record<string, string>;
  maxRetries?: number;
  config?: Record<string, string> | null;
  traceParams?: TraceParams;
  throwOnError?: boolean; // default is true
};

type FetchLLMCompletionParams = LLMCompletionParams & {
  streaming: boolean;
  tools?: LLMToolDefinition[];
};

export async function fetchLLMCompletion(
  // eslint-disable-next-line no-unused-vars
  params: LLMCompletionParams & {
    streaming: true;
  },
): Promise<{
  completion: IterableReadableStream<Uint8Array>;
  processTracedEvents: ProcessTracedEvents;
}>;

export async function fetchLLMCompletion(
  // eslint-disable-next-line no-unused-vars
  params: LLMCompletionParams & {
    streaming: false;
  },
): Promise<{
  completion: string;
  processTracedEvents: ProcessTracedEvents;
}>;

export async function fetchLLMCompletion(
  // eslint-disable-next-line no-unused-vars
  params: LLMCompletionParams & {
    streaming: false;
    structuredOutputSchema: ZodSchema;
  },
): Promise<{
  completion: Record<string, unknown>;
  processTracedEvents: ProcessTracedEvents;
}>;

export async function fetchLLMCompletion(
  // eslint-disable-next-line no-unused-vars
  params: LLMCompletionParams & {
    tools: LLMToolDefinition[];
    streaming: false;
  },
): Promise<{
  completion: ToolCallResponse;
  processTracedEvents: ProcessTracedEvents;
}>;

export async function fetchLLMCompletion(
  params: FetchLLMCompletionParams,
): Promise<{
  completion:
    | string
    | IterableReadableStream<Uint8Array>
    | Record<string, unknown>
    | ToolCallResponse;
  processTracedEvents: ProcessTracedEvents;
}> {
  // the apiKey must never be printed to the console
  const {
    messages,
    tools,
    modelParams,
    streaming,
    callbacks,
    apiKey,
    baseURL,
    maxRetries,
    config,
    traceParams,
    extraHeaders,
    throwOnError = true,
  } = params;

  let finalCallbacks: BaseCallbackHandler[] | undefined = callbacks ?? [];
  let processTracedEvents: ProcessTracedEvents = () => Promise.resolve();

  if (traceParams) {
    const handler = new CallbackHandler({
      _projectId: traceParams.projectId,
      _isLocalEventExportEnabled: true,
      environment: traceParams.environment,
    });
    finalCallbacks.push(handler);

    processTracedEvents = async () => {
      try {
        const events = await handler.langfuse._exportLocalEvents(
          traceParams.projectId,
        );
        await processEventBatch(
          JSON.parse(JSON.stringify(events)), // stringify to emulate network event batch from network call
          traceParams.authCheck,
          { isLangfuseInternal: true },
        );
      } catch (e) {
        logger.error("Failed to process traced events", { error: e });
      }
    };
  }

  finalCallbacks = finalCallbacks.length > 0 ? finalCallbacks : undefined;

  // Helper function to safely stringify content
  const safeStringify = (content: any): string => {
    try {
      return JSON.stringify(content);
    } catch {
      return "[Unserializable content]";
    }
  };

  let finalMessages: BaseMessage[];
  // VertexAI requires at least 1 user message
  if (modelParams.adapter === LLMAdapter.VertexAI && messages.length === 1) {
    const safeContent =
      typeof messages[0].content === "string"
        ? messages[0].content
        : JSON.stringify(messages[0].content);
    finalMessages = [new HumanMessage(safeContent)];
  } else {
    finalMessages = messages.map((message) => {
      // For arbitrary content types, convert to string safely
      const safeContent =
        typeof message.content === "string"
          ? message.content
          : safeStringify(message.content);

      if (message.role === ChatMessageRole.User)
        return new HumanMessage(safeContent);
      if (
        message.role === ChatMessageRole.System ||
        message.role === ChatMessageRole.Developer
      )
        return new SystemMessage(safeContent);

      if (message.type === ChatMessageType.ToolResult) {
        return new ToolMessage({
          content: safeContent,
          tool_call_id: message.toolCallId,
        });
      }

      return new AIMessage({
        content: safeContent,
        tool_calls:
          message.type === ChatMessageType.AssistantToolCall
            ? (message.toolCalls as any)
            : undefined,
      });
    });
  }

  finalMessages = finalMessages.filter(
    (m) => m.content.length > 0 || "tool_calls" in m,
  );

  // Common proxy configuration for all adapters
  const proxyUrl = env.HTTPS_PROXY;
  const proxyAgent = proxyUrl ? new HttpsProxyAgent(proxyUrl) : undefined;

  let chatModel:
    | ChatOpenAI
    | ChatAnthropic
    | ChatBedrockConverse
    | ChatVertexAI
    | ChatGoogleGenerativeAI;
  if (modelParams.adapter === LLMAdapter.Anthropic) {
    chatModel = new ChatAnthropic({
      anthropicApiKey: apiKey,
      anthropicApiUrl: baseURL,
      modelName: modelParams.model,
      temperature: modelParams.temperature,
      maxTokens: modelParams.max_tokens,
      topP: modelParams.top_p,
      callbacks: finalCallbacks,
      clientOptions: {
        maxRetries,
        timeout: 1000 * 60 * 2, // 2 minutes timeout
        ...(proxyAgent && { httpAgent: proxyAgent }),
      },
      invocationKwargs: modelParams.providerOptions,
    });
  } else if (modelParams.adapter === LLMAdapter.OpenAI) {
    chatModel = new ChatOpenAI({
      openAIApiKey: apiKey,
      modelName: modelParams.model,
      temperature: modelParams.temperature,
      maxTokens: modelParams.max_tokens,
      topP: modelParams.top_p,
      streamUsage: false, // https://github.com/langchain-ai/langchainjs/issues/6533
      callbacks: finalCallbacks,
      maxRetries,
      configuration: {
        baseURL,
        defaultHeaders: extraHeaders,
        ...(proxyAgent && { httpAgent: proxyAgent }),
      },
      modelKwargs: modelParams.providerOptions,
      timeout: 1000 * 60 * 2, // 2 minutes timeout
    });
  } else if (modelParams.adapter === LLMAdapter.Azure) {
    chatModel = new AzureChatOpenAI({
      azureOpenAIApiKey: apiKey,
      azureOpenAIBasePath: baseURL,
      azureOpenAIApiDeploymentName: modelParams.model,
      azureOpenAIApiVersion: "2025-02-01-preview",
      temperature: modelParams.temperature,
      maxTokens: modelParams.max_tokens,
      topP: modelParams.top_p,
      callbacks: finalCallbacks,
      maxRetries,
      timeout: 1000 * 60 * 2, // 2 minutes timeout
      configuration: {
        defaultHeaders: extraHeaders,
        ...(proxyAgent && { httpAgent: proxyAgent }),
      },
      modelKwargs: modelParams.providerOptions,
    });
  } else if (modelParams.adapter === LLMAdapter.Bedrock) {
    const { region } = BedrockConfigSchema.parse(config);
    // Handle both explicit credentials and default provider chain
    const credentials =
      apiKey === BEDROCK_USE_DEFAULT_CREDENTIALS && !isLangfuseCloud
        ? undefined // undefined = use AWS SDK default credential provider chain
        : BedrockCredentialSchema.parse(JSON.parse(apiKey));

    chatModel = new ChatBedrockConverse({
      model: modelParams.model,
      region,
      credentials,
      temperature: modelParams.temperature,
      maxTokens: modelParams.max_tokens,
      topP: modelParams.top_p,
      callbacks: finalCallbacks,
      maxRetries,
      timeout: 1000 * 60 * 2, // 2 minutes timeout
      additionalModelRequestFields: modelParams.providerOptions as any,
    });
  } else if (modelParams.adapter === LLMAdapter.VertexAI) {
    const credentials = GCPServiceAccountKeySchema.parse(JSON.parse(apiKey));
    const { location } = config
      ? VertexAIConfigSchema.parse(config)
      : { location: undefined };

    // Requests time out after 60 seconds for both public and private endpoints by default
    // Reference: https://cloud.google.com/vertex-ai/docs/predictions/get-online-predictions#send-request
    chatModel = new ChatVertexAI({
      modelName: modelParams.model,
      temperature: modelParams.temperature,
      maxOutputTokens: modelParams.max_tokens,
      topP: modelParams.top_p,
      callbacks: finalCallbacks,
      maxRetries,
      location,
      authOptions: {
        projectId: credentials.project_id,
        credentials,
      },
    });
  } else if (modelParams.adapter === LLMAdapter.GoogleAIStudio) {
    chatModel = new ChatGoogleGenerativeAI({
      model: modelParams.model,
      temperature: modelParams.temperature,
      maxOutputTokens: modelParams.max_tokens,
      topP: modelParams.top_p,
      callbacks: finalCallbacks,
      maxRetries,
      apiKey,
    });
  } else if (modelParams.adapter === LLMAdapter.PowerRAG) {
    // PowerRAG uses custom API format, handle separately
    const powerRAGCompletion = await handlePowerRAGCompletion({
      messages: finalMessages,
      apiKey,
      baseURL,
      extraHeaders,
      streaming,
      callbacks: finalCallbacks,
      modelParams,
      proxyAgent,
      traceParams,
    });

    return {
      completion: powerRAGCompletion,
      processTracedEvents,
    };
  } else {
    // eslint-disable-next-line no-unused-vars
    const _exhaustiveCheck: never = modelParams.adapter;
    throw new Error(
      `This model provider is not supported: ${_exhaustiveCheck}`,
    );
  }

  const runConfig = {
    callbacks: finalCallbacks,
    runId: traceParams?.traceId,
    runName: traceParams?.traceName,
  };

  try {
    logger.info(
      `ğŸ¯ å¼€å§‹ LLM è°ƒç”¨ - æ¨¡å‹: ${modelParams.model}, Provider: ${modelParams.provider}`,
      {
        model: modelParams.model,
        provider: modelParams.provider,
        adapter: modelParams.adapter,
        baseURL,
        hasStructuredOutput: !!params.structuredOutputSchema,
        hasTools: !!(tools && tools.length > 0),
        streaming,
        messagesCount: finalMessages.length,
      },
    );

    if (params.structuredOutputSchema) {
      logger.info(`ğŸ”§ ä½¿ç”¨ç»“æ„åŒ–è¾“å‡ºæ¨¡å¼ - æ¨¡å‹: ${modelParams.model}`, {
        model: modelParams.model,
        schemaType: params.structuredOutputSchema.constructor.name,
      });

      // åƒé—®æ¨¡å‹ç‰¹æ®Šå¤„ç†ï¼šå½“ä½¿ç”¨ response_format: { "type": "json_object" } æ—¶ï¼Œ
      // åƒé—®æ¨¡å‹è¦æ±‚æ¶ˆæ¯å†…å®¹ä¸­å¿…é¡»åŒ…å« "json" è¿™ä¸ªè¯
      let processedMessages = finalMessages;
      if (
        modelParams.model.toLowerCase().includes("qwen") &&
        (modelParams.provider.toLowerCase().includes("qianwen") ||
          modelParams.provider.toLowerCase().includes("qwen"))
      ) {
        logger.info(
          `ğŸ”§ æ£€æµ‹åˆ°åƒé—®æ¨¡å‹ï¼Œæ·»åŠ  JSON å…³é”®è¯ - æ¨¡å‹: ${modelParams.model}`,
          {
            model: modelParams.model,
            provider: modelParams.provider,
          },
        );

        processedMessages = finalMessages.map((message) => {
          if (
            message._getType() === "human" &&
            typeof message.content === "string"
          ) {
            // æ£€æŸ¥æ¶ˆæ¯å†…å®¹æ˜¯å¦å·²ç»åŒ…å« "json" å…³é”®è¯
            const content = message.content.toLowerCase();
            if (!content.includes("json")) {
              // åœ¨æ¶ˆæ¯å¼€å¤´æ·»åŠ  JSON å…³é”®è¯ï¼Œå¹¶æ˜ç¡®æŒ‡å®šå­—æ®µåç§°
              const enhancedContent = `Please respond with a JSON object containing exactly two fields: "reasoning" (string) and "score" (number). ${message.content}`;
              logger.info(
                `ğŸ”§ ä¸ºåƒé—®æ¨¡å‹æ·»åŠ  JSON å…³é”®è¯ - åŸå§‹å†…å®¹é•¿åº¦: ${message.content.length}, å¢å¼ºåé•¿åº¦: ${enhancedContent.length}`,
                {
                  model: modelParams.model,
                  originalContentPreview:
                    message.content.substring(0, 100) +
                    (message.content.length > 100 ? "..." : ""),
                  enhancedContentPreview:
                    enhancedContent.substring(0, 100) +
                    (enhancedContent.length > 100 ? "..." : ""),
                },
              );
              return new HumanMessage(enhancedContent);
            }
          }
          return message;
        });
      }

      const result = await (chatModel as ChatOpenAI) // Typecast necessary due to https://github.com/langchain-ai/langchainjs/issues/6795
        .withStructuredOutput(params.structuredOutputSchema)
        .invoke(processedMessages, runConfig);

      logger.info(`âœ… ç»“æ„åŒ–è¾“å‡ºè°ƒç”¨æˆåŠŸ - æ¨¡å‹: ${modelParams.model}`, {
        model: modelParams.model,
        resultType: typeof result,
        hasResult: !!result,
      });

      return {
        completion: result,
        processTracedEvents,
      };
    }

    if (tools && tools.length > 0) {
      logger.info(
        `ğŸ”§ ä½¿ç”¨å·¥å…·è°ƒç”¨æ¨¡å¼ - æ¨¡å‹: ${modelParams.model}, å·¥å…·æ•°é‡: ${tools.length}`,
        {
          model: modelParams.model,
          toolsCount: tools.length,
        },
      );

      const langchainTools = tools.map((tool) => ({
        type: "function",
        function: tool,
      }));

      const result = await chatModel
        .bindTools(langchainTools)
        .invoke(finalMessages, runConfig);

      const parsed = ToolCallResponseSchema.safeParse(result);
      if (!parsed.success) throw Error("Failed to parse LLM tool call result");

      logger.info(`âœ… å·¥å…·è°ƒç”¨æˆåŠŸ - æ¨¡å‹: ${modelParams.model}`, {
        model: modelParams.model,
        resultType: typeof result,
      });

      return {
        completion: parsed.data,
        processTracedEvents,
      };
    }

    if (streaming) {
      logger.info(`ğŸ”§ ä½¿ç”¨æµå¼è¾“å‡ºæ¨¡å¼ - æ¨¡å‹: ${modelParams.model}`, {
        model: modelParams.model,
      });

      const result = await chatModel
        .pipe(new BytesOutputParser())
        .stream(finalMessages, runConfig);

      logger.info(`âœ… æµå¼è¾“å‡ºè°ƒç”¨æˆåŠŸ - æ¨¡å‹: ${modelParams.model}`, {
        model: modelParams.model,
        resultType: typeof result,
      });

      return {
        completion: result,
        processTracedEvents,
      };
    }

    logger.info(`ğŸ”§ ä½¿ç”¨æ ‡å‡†è¾“å‡ºæ¨¡å¼ - æ¨¡å‹: ${modelParams.model}`, {
      model: modelParams.model,
    });

    const result = await chatModel
      .pipe(new StringOutputParser())
      .invoke(finalMessages, runConfig);

    logger.info(`âœ… æ ‡å‡†è¾“å‡ºè°ƒç”¨æˆåŠŸ - æ¨¡å‹: ${modelParams.model}`, {
      model: modelParams.model,
      resultType: typeof result,
      resultLength: typeof result === "string" ? result.length : "N/A",
    });

    return {
      completion: result,
      processTracedEvents,
    };
  } catch (error) {
    logger.error(
      `âŒ LLM è°ƒç”¨å¤±è´¥ - æ¨¡å‹: ${modelParams.model}, é”™è¯¯: ${error}`,
      {
        model: modelParams.model,
        provider: modelParams.provider,
        error: error instanceof Error ? error.message : String(error),
        errorStack: error instanceof Error ? error.stack : undefined,
      },
    );

    if (throwOnError) {
      throw error;
    }

    return { completion: "", processTracedEvents };
  }
}

// PowerRAG specific handler
async function handlePowerRAGCompletion({
  messages,
  apiKey,
  baseURL,
  extraHeaders,
  streaming,
  callbacks,
  modelParams,
  proxyAgent,
  traceParams, // æ·»åŠ traceParamså‚æ•°
}: {
  messages: BaseMessage[];
  apiKey: string;
  baseURL?: string;
  extraHeaders?: Record<string, string>;
  streaming: boolean;
  callbacks?: BaseCallbackHandler[];
  modelParams: ModelParams;
  proxyAgent?: any;
  traceParams?: TraceParams; // æ·»åŠ traceParamsç±»å‹
}): Promise<string> {
  // æ£€æŸ¥æ˜¯å¦æœ‰Langfuse CallbackHandler
  const langfuseHandler = callbacks?.find(
    (callback) => callback.constructor.name === "CallbackHandler",
  );

  // è·å–traceIdï¼Œä¼˜å…ˆä½¿ç”¨traceParamsä¸­çš„traceId
  const traceId = traceParams?.traceId;

  if (!traceId) {
    logger.warn("PowerRAG: æœªæä¾›traceIdï¼Œå°†æ— æ³•åˆ›å»ºæ‰‹åŠ¨åŸ‹ç‚¹", {
      hasTraceParams: !!traceParams,
      hasCallbacks: !!callbacks,
    });
  }

  // Convert LangChain messages to PowerRAG format
  // First try to find human messages
  let query = messages
    .filter((msg) => msg._getType() === "human")
    .map((msg) =>
      typeof msg.content === "string"
        ? msg.content
        : JSON.stringify(msg.content),
    )
    .join("\n");

  // If no human messages found, try to use system messages or any other message type
  if (!query) {
    query = messages
      .filter((msg) => msg._getType() === "system" || msg._getType() === "ai")
      .map((msg) =>
        typeof msg.content === "string"
          ? msg.content
          : JSON.stringify(msg.content),
      )
      .join("\n");
  }

  // If still no query, use the first available message
  if (!query && messages.length > 0) {
    const firstMessage = messages[0];
    query =
      typeof firstMessage.content === "string"
        ? firstMessage.content
        : JSON.stringify(firstMessage.content);
  }

  if (!query) {
    throw new Error("No user message found for PowerRAG query");
  }

  // Prepare PowerRAG request payload
  const powerRAGPayload = {
    inputs: {},
    query: query,
    response_mode: streaming ? "blocking" : "streaming", // Use appropriate response mode
    conversation_id: "",
    user: "abc-123", // Use consistent user ID
    files: [], // Can be extended to support file uploads
  };

  // Prepare headers
  const headers: Record<string, string> = {
    "Content-Type": "application/json",
    ...extraHeaders,
  };

  // Add Authorization header if API key is provided
  if (apiKey && apiKey.trim() !== "") {
    headers.Authorization = `Bearer ${apiKey}`;
  } else {
    logger.warn("PowerRAG API key is empty or not provided", {
      hasApiKey: false,
      apiKeyValue: apiKey,
    });
  }

  const requestUrl =
    baseURL ||
    `${env.LANGFUSE_POWERRAG_PROTOCOL}://${env.LANGFUSE_POWERRAG_HOST}:${env.LANGFUSE_POWERRAG_PORT}/v1/chat-messages`;

  // æ‰“å°è¯·æ±‚ä½“
  console.log("ğŸ” PowerRAG è¯·æ±‚ä½“:");
  console.log(JSON.stringify(powerRAGPayload, null, 2));

  // è¯¦ç»†çš„è¯·æ±‚æ—¥å¿—
  logger.info("PowerRAG API request", {
    url: requestUrl,
    hasApiKey: !!apiKey,
    streaming,
    traceId,
    projectId: traceParams?.projectId,
    environment: traceParams?.environment,
    traceName: traceParams?.traceName,
    queryLength: query.length,
    queryPreview: query.substring(0, 200) + (query.length > 200 ? "..." : ""),
    headers: Object.keys(headers),
    payloadSize: JSON.stringify(powerRAGPayload).length,
  });

  // å¦‚æœæœ‰traceParamsï¼Œå¼ºåˆ¶ä½¿ç”¨æ‰‹åŠ¨åŸ‹ç‚¹ï¼Œè·³è¿‡callbacks
  if (traceParams && traceId) {
    logger.info(
      "PowerRAG: æ£€æµ‹åˆ°traceParamsï¼Œå¼ºåˆ¶ä½¿ç”¨æ‰‹åŠ¨åŸ‹ç‚¹ï¼Œè·³è¿‡callbacks",
      {
        traceId,
        projectId: traceParams.projectId,
        environment: traceParams.environment,
        reason: "ç¡®ä¿traceIdä¸€è‡´æ€§å’Œæ‰‹åŠ¨åŸ‹ç‚¹æ§åˆ¶",
      },
    );
  } else if (langfuseHandler) {
    logger.info("PowerRAG: æœªæ£€æµ‹åˆ°traceParamsï¼Œä½¿ç”¨callbacksé€»è¾‘", {
      traceId,
      hasTraceParams: !!traceParams,
      hasTraceId: !!traceId,
    });
    try {
      // å°è¯•è§¦å‘callbacksçš„LLMå¼€å§‹äº‹ä»¶
      // LangChain APIéœ€è¦: handleLLMStart(llm: Serialized, prompts: string[], runId: string, ...)
      await langfuseHandler.handleLLMStart?.(
        {
          name: modelParams.model,
          id: [traceId || "powerrag-unknown"], // ä½¿ç”¨traceIdæˆ–ç”Ÿæˆä¸€ä¸ªé»˜è®¤ID
          lc: 1, // æ·»åŠ å¿…éœ€çš„lcå±æ€§
          type: "not_implemented", // æ·»åŠ å¿…éœ€çš„typeå±æ€§
        },
        [query],
        traceId || "powerrag-unknown",
      );
    } catch (error) {
      logger.warn("PowerRAG: è§¦å‘callbackså¤±è´¥ï¼Œå°†ä½¿ç”¨æ‰‹åŠ¨traceåˆ›å»º", {
        error: error instanceof Error ? error.message : String(error),
        traceId,
      });
    }
  }

  const startTime = Date.now();
  let response: Response;
  let text: string;

  try {
    response = await fetch(requestUrl, {
      method: "POST",
      headers,
      body: JSON.stringify(powerRAGPayload),
      ...(proxyAgent && { agent: proxyAgent }),
    });

    if (!response.ok) {
      const errorText = await response.text();
      logger.error("PowerRAG API error response", {
        status: response.status,
        statusText: response.statusText,
        errorText,
        url: requestUrl,
        traceId,
      });
      throw new Error(
        `PowerRAG API error: ${response.status} ${response.statusText} - ${errorText}`,
      );
    }

    // Handle response based on streaming mode
    text = await response.text();

    // æ‰“å°è¿”å›ç»“æœ
    console.log("ğŸ“¥ PowerRAG è¿”å›ç»“æœ:");
    console.log("çŠ¶æ€ç :", response.status);
    console.log("å“åº”é•¿åº¦:", text.length);
    console.log("å“åº”å†…å®¹:", text);

    // è¯¦ç»†çš„å“åº”æ—¥å¿—
    logger.info("PowerRAG API response", {
      status: response.status,
      responseLength: text.length,
      streaming,
      traceId,
      projectId: traceParams?.projectId,
      environment: traceParams?.environment,
      responsePreview:
        text.substring(0, 200) + (text.length > 200 ? "..." : ""),
      startTime: new Date(startTime).toISOString(),
    });

    let completion: string;

    if (streaming) {
      // Handle streaming response
      try {
        // Try to parse as JSON first (PowerRAG format)
        const parsed = JSON.parse(text);

        if (parsed.answer) {
          completion = parsed.answer;
        } else if (parsed.content) {
          completion = parsed.content;
        } else {
          completion = JSON.stringify(parsed);
        }
      } catch (e) {
        // Fallback to Server-Sent Events format for streaming
        logger.info("PowerRAG parsing as Server-Sent Events", {
          parseError: e instanceof Error ? e.message : String(e),
          traceId,
        });

        const lines = text.split("\n");
        let content = "";
        let hasMessageEvents = false;
        let messageEndAnswer = "";

        for (const line of lines) {
          if (line.startsWith("data: ")) {
            const data = line.slice(6);
            if (data.trim() === "") continue;

            try {
              const parsed = JSON.parse(data);

              if (parsed.event === "message") {
                hasMessageEvents = true;
                if (parsed.answer) {
                  // Handle PowerRAG streaming format where answer contains the content
                  // Filter out special markers and empty content
                  const answer = parsed.answer;
                  if (
                    answer &&
                    answer.trim() !== "" &&
                    !answer.includes("<Thinking Begin>") &&
                    !answer.includes("<Thinking End>") &&
                    !answer.includes("<Action Begin>") &&
                    !answer.includes("<Final Answer Begin>")
                  ) {
                    content += answer;
                  }
                }
              } else if (parsed.event === "message_end") {
                // Store message_end answer in case we need it
                if (parsed.answer) {
                  messageEndAnswer = parsed.answer;
                }
                break;
              } else if (parsed.content) {
                content += parsed.content;
              }
            } catch (e) {
              // Ignore parsing errors
              logger.debug("PowerRAG SSE line parse failed", {
                line: line.substring(0, 100),
                error: e instanceof Error ? e.message : String(e),
                traceId,
              });
            }
          }
        }

        // Return logic based on business rules:
        // 1. If we have message events, return the accumulated content from message events
        // 2. If no message events, return the answer from message_end event
        if (hasMessageEvents) {
          completion = content;
        } else {
          completion = messageEndAnswer;
        }
      }
    } else {
      // Handle blocking response
      try {
        const parsed = JSON.parse(text);

        if (parsed.answer) {
          completion = parsed.answer;
        } else if (parsed.content) {
          completion = parsed.content;
        } else {
          completion = JSON.stringify(parsed);
        }
      } catch (e) {
        // If not JSON, return the raw text
        completion = text;
      }
    }

    const endTime = Date.now();
    const duration = endTime - startTime;

    // å¦‚æœæœ‰traceParamsï¼Œè·³è¿‡callbacksï¼Œå¼ºåˆ¶ä½¿ç”¨æ‰‹åŠ¨åŸ‹ç‚¹
    if (traceParams && traceId) {
      logger.info("PowerRAG: è·³è¿‡callbacksï¼Œå¼ºåˆ¶ä½¿ç”¨æ‰‹åŠ¨åŸ‹ç‚¹", {
        traceId,
        projectId: traceParams.projectId,
        reason: "ç¡®ä¿traceIdä¸€è‡´æ€§å’Œæ‰‹åŠ¨åŸ‹ç‚¹æ§åˆ¶",
      });
    } else if (langfuseHandler) {
      // å¦‚æœæ²¡æœ‰traceParamsï¼Œå°è¯•ä½¿ç”¨callbacks
      try {
        await langfuseHandler.handleLLMEnd?.(
          {
            generations: [[{ text: completion }]],
            llmOutput: {},
          },
          traceId || "powerrag-unknown", // runIdä½œä¸ºç¬¬äºŒä¸ªå‚æ•°
        );
        logger.info("PowerRAG: æˆåŠŸè§¦å‘callbacksï¼Œtraceå°†é€šè¿‡callbacksåˆ›å»º", {
          traceId,
        });
        return completion;
      } catch (error) {
        logger.warn(
          "PowerRAG: è§¦å‘callbacksç»“æŸäº‹ä»¶å¤±è´¥ï¼Œå°†ä½¿ç”¨æ‰‹åŠ¨traceåˆ›å»º",
          {
            error: error instanceof Error ? error.message : String(error),
            traceId,
          },
        );
      }
    }

    // å¦‚æœæ²¡æœ‰Langfuse CallbackHandleræˆ–callbackså¤±è´¥ï¼Œæ‰‹åŠ¨åˆ›å»ºtrace
    logger.info("PowerRAG: ä½¿ç”¨æ‰‹åŠ¨traceåˆ›å»ºé€»è¾‘", {
      traceId,
      hasTraceParams: !!traceParams,
    });

    // å¦‚æœæœ‰traceParamsï¼Œæ‰‹åŠ¨åˆ›å»ºtraceè®°å½•
    if (traceParams && traceId) {
      logger.info("PowerRAG: å¼€å§‹æ‰‹åŠ¨åˆ›å»ºtrace", {
        traceId,
        projectId: traceParams.projectId,
        environment: traceParams.environment,
        traceName: traceParams.traceName || "PowerRAG Query",
        inputLength: query.length,
        outputLength: completion.length,
        duration,
        startTime: new Date(startTime).toISOString(),
        endTime: new Date(endTime).toISOString(),
      });

      try {
        // ç¡®ä¿environmentå€¼ç¬¦åˆå…¬å…±æ¨¡å¼éªŒè¯è§„åˆ™
        let safeEnvironment = traceParams.environment;
        // æ£€æŸ¥ç¯å¢ƒåæ˜¯å¦ç¬¦åˆéªŒè¯è§„åˆ™
        if (
          safeEnvironment &&
          (safeEnvironment.startsWith("langfuse") ||
            safeEnvironment.length > 40)
        ) {
          // å¦‚æœç¯å¢ƒåä»¥langfuseå¼€å¤´æˆ–è¶…è¿‡40å­—ç¬¦ï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤å€¼
          safeEnvironment = "prompt-experiment";
          logger.warn("PowerRAG: ç¯å¢ƒåä¸ç¬¦åˆéªŒè¯è§„åˆ™ï¼Œä½¿ç”¨é»˜è®¤å€¼", {
            originalEnvironment: traceParams.environment,
            safeEnvironment,
            reason: "ç¯å¢ƒåä¸èƒ½ä»¥langfuseå¼€å¤´ä¸”é•¿åº¦ä¸èƒ½è¶…è¿‡40å­—ç¬¦",
          });
        }

        await createManualTrace({
          traceId,
          projectId: traceParams.projectId,
          environment: safeEnvironment,
          name: traceParams.traceName || "PowerRAG Query",
          input: query,
          output: completion,
          metadata: {
            provider: "PowerRAG",
            model: modelParams.model,
            adapter: modelParams.adapter,
            duration,
            startTime: new Date(startTime),
            endTime: new Date(endTime),
            streaming,
            manualTracing: true, // æ ‡è®°ä¸ºæ‰‹åŠ¨åŸ‹ç‚¹
          },
        });
        logger.info("PowerRAG: æ‰‹åŠ¨traceåˆ›å»ºæˆåŠŸ", {
          traceId,
          projectId: traceParams.projectId,
          environment: traceParams.environment,
          traceName: traceParams.traceName || "PowerRAG Query",
          completion: "traceå·²æˆåŠŸåˆ›å»ºå¹¶åŠ å…¥å¤„ç†é˜Ÿåˆ—",
        });
      } catch (error) {
        logger.error("PowerRAG: æ‰‹åŠ¨traceåˆ›å»ºå¤±è´¥", {
          error: error instanceof Error ? error.message : String(error),
          errorStack: error instanceof Error ? error.stack : undefined,
          traceId,
          projectId: traceParams.projectId,
          environment: traceParams.environment,
          traceName: traceParams.traceName || "PowerRAG Query",
          completion: "traceåˆ›å»ºå¤±è´¥ï¼Œéœ€è¦æ£€æŸ¥é”™è¯¯åŸå› ",
        });
      }
    } else {
      logger.warn("PowerRAG: æ— æ³•åˆ›å»ºæ‰‹åŠ¨trace", {
        hasTraceParams: !!traceParams,
        hasTraceId: !!traceId,
        traceParams: traceParams
          ? {
              projectId: traceParams.projectId,
              environment: traceParams.environment,
              traceName: traceParams.traceName,
            }
          : null,
        completion: "ç¼ºå°‘å¿…è¦çš„traceå‚æ•°",
      });
    }

    // æœ€ç»ˆå®Œæˆæ—¥å¿—
    logger.info("PowerRAG: è°ƒç”¨å®Œæˆ", {
      traceId,
      projectId: traceParams?.projectId,
      environment: traceParams?.environment,
      completion: "PowerRAGè°ƒç”¨å·²å®Œå…¨å¤„ç†å®Œæˆï¼ŒåŒ…æ‹¬traceåˆ›å»º",
      finalCompletionLength: completion.length,
      hasManualTrace: !!(traceParams && traceId),
      hasCallbacks: !!langfuseHandler,
    });

    return completion;
  } catch (error) {
    const endTime = Date.now();
    const duration = endTime - startTime;

    // å¦‚æœæœ‰traceParamsï¼Œè·³è¿‡callbacksé”™è¯¯å¤„ç†ï¼Œå¼ºåˆ¶ä½¿ç”¨æ‰‹åŠ¨åŸ‹ç‚¹
    if (traceParams && traceId) {
      logger.info("PowerRAG: è·³è¿‡callbacksé”™è¯¯å¤„ç†ï¼Œå¼ºåˆ¶ä½¿ç”¨æ‰‹åŠ¨åŸ‹ç‚¹", {
        traceId,
        projectId: traceParams.projectId,
        reason: "ç¡®ä¿traceIdä¸€è‡´æ€§å’Œæ‰‹åŠ¨åŸ‹ç‚¹æ§åˆ¶",
      });
    } else if (langfuseHandler) {
      // å¦‚æœæ²¡æœ‰traceParamsï¼Œå°è¯•ä½¿ç”¨callbacksé”™è¯¯å¤„ç†
      try {
        await langfuseHandler.handleLLMError?.(
          error,
          traceId || "powerrag-unknown",
        );
      } catch (callbackError) {
        logger.warn("PowerRAG: è§¦å‘callbacksé”™è¯¯äº‹ä»¶å¤±è´¥", {
          error:
            callbackError instanceof Error
              ? callbackError.message
              : String(callbackError),
          traceId,
        });
      }
    }

    // å¦‚æœæœ‰traceParamsï¼Œæ‰‹åŠ¨åˆ›å»ºé”™è¯¯traceè®°å½•
    if (traceParams && traceId) {
      try {
        // ç¡®ä¿environmentå€¼ç¬¦åˆå…¬å…±æ¨¡å¼éªŒè¯è§„åˆ™
        let safeEnvironment = traceParams.environment;
        if (
          safeEnvironment &&
          (safeEnvironment.startsWith("langfuse") ||
            safeEnvironment.length > 40)
        ) {
          safeEnvironment = "prompt-experiment";
          logger.warn("PowerRAG: é”™è¯¯å¤„ç†ä¸­ç¯å¢ƒåä¸ç¬¦åˆéªŒè¯è§„åˆ™ï¼Œä½¿ç”¨é»˜è®¤å€¼", {
            originalEnvironment: traceParams.environment,
            safeEnvironment,
          });
        }

        await createManualTrace({
          traceId,
          projectId: traceParams.projectId,
          environment: safeEnvironment,
          name: traceParams.traceName || "PowerRAG Query (Error)",
          input: query,
          output: null,
          error: error instanceof Error ? error.message : String(error),
          metadata: {
            provider: "PowerRAG",
            model: modelParams.model,
            adapter: modelParams.adapter,
            duration,
            startTime: new Date(startTime),
            endTime: new Date(endTime),
            streaming,
            manualTracing: true, // æ ‡è®°ä¸ºæ‰‹åŠ¨åŸ‹ç‚¹
            error: true,
          },
        });
        logger.info("PowerRAG: é”™è¯¯traceæ‰‹åŠ¨åˆ›å»ºæˆåŠŸ", {
          traceId,
          projectId: traceParams.projectId,
        });
      } catch (traceError) {
        logger.error("PowerRAG: é”™è¯¯traceæ‰‹åŠ¨åˆ›å»ºå¤±è´¥", {
          error:
            traceError instanceof Error
              ? traceError.message
              : String(traceError),
          errorStack:
            traceError instanceof Error ? traceError.stack : undefined,
          errorName: traceError instanceof Error ? traceError.name : undefined,
          errorConstructor: traceError?.constructor?.name,
          traceId,
          projectId: traceParams.projectId,
          context: {
            originalError:
              error instanceof Error ? error.message : String(error),
            hasTraceParams: !!traceParams,
            hasTraceId: !!traceId,
            duration,
            streaming,
          },
          completion:
            "PowerRAGé”™è¯¯traceæ‰‹åŠ¨åˆ›å»ºå¤±è´¥ï¼Œè®°å½•è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯å’Œä¸Šä¸‹æ–‡",
        });
      }
    }

    logger.error("PowerRAG API call failed", {
      error: error instanceof Error ? error.message : String(error),
      errorStack: error instanceof Error ? error.stack : undefined,
      errorName: error instanceof Error ? error.name : undefined,
      url: requestUrl,
      traceId,
      payload: {
        ...powerRAGPayload,
        query: powerRAGPayload.query.substring(0, 100) + "...",
      },
      headers: {
        ...headers,
        Authorization: headers.Authorization ? "Bearer ***" : undefined,
      },
      proxyAgent: !!proxyAgent,
      networkInfo: {
        host: env.LANGFUSE_POWERRAG_HOST,
        port: env.LANGFUSE_POWERRAG_PORT,
        protocol: env.LANGFUSE_POWERRAG_PROTOCOL,
      },
      requestInfo: {
        method: "POST",
        bodySize: JSON.stringify(powerRAGPayload).length,
        hasApiKey: !!apiKey,
        streaming,
      },
    });
    throw error;
  }
}

// æ‰‹åŠ¨åˆ›å»ºtraceçš„è¾…åŠ©å‡½æ•°
async function createManualTrace({
  traceId,
  projectId,
  environment,
  name,
  input,
  output,
  error,
  metadata,
}: {
  traceId: string;
  projectId: string;
  environment: string;
  name: string;
  input: string;
  output: string | null;
  error?: string;
  metadata: Record<string, any>;
}): Promise<void> {
  try {
    logger.info("å¼€å§‹åˆ›å»ºæ‰‹åŠ¨trace", {
      traceId,
      projectId,
      environment,
      name,
      hasError: !!error,
      inputLength: input.length,
      outputLength: output?.length || 0,
    });

    // ä½¿ç”¨é™æ€å¯¼å…¥ï¼Œç¡®ä¿æ¨¡å—å¯ç”¨
    const { processEventBatch } = await import(
      "../ingestion/processEventBatch.js"
    );
    const { eventTypes } = await import("../ingestion/types.js");
    const { v4: uuidv4 } = await import("uuid");

    // åˆ›å»ºtraceäº‹ä»¶
    const eventId = uuidv4();

    // ä½¿ç”¨ä¼ å…¥çš„æ—¶é—´ä¿¡æ¯ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨å½“å‰æ—¶é—´
    const startTime =
      metadata?.startTime instanceof Date ? metadata.startTime : new Date();
    const endTime =
      metadata?.endTime instanceof Date ? metadata.endTime : new Date();

    // æ˜ç¡®è®¾ç½®ä¸ºä¸œ8åŒºï¼ˆUTC+8ï¼‰
    // è·å–UTCæ—¶é—´å¹¶åŠ ä¸Š8å°æ—¶åç§»
    const utcTime = new Date(startTime.getTime() + 8 * 60 * 60 * 1000);

    // åˆ›å»ºä¸œ8åŒºæ—¶é—´çš„ISOå­—ç¬¦ä¸²ï¼Œæ ¼å¼ï¼šYYYY-MM-DDTHH:mm:ss.sss+08:00
    const year = utcTime.getUTCFullYear();
    const month = String(utcTime.getUTCMonth() + 1).padStart(2, "0");
    const day = String(utcTime.getUTCDate()).padStart(2, "0");
    const hours = String(utcTime.getUTCHours()).padStart(2, "0");
    const minutes = String(utcTime.getUTCMinutes()).padStart(2, "0");
    const seconds = String(utcTime.getUTCSeconds()).padStart(2, "0");
    const milliseconds = String(utcTime.getUTCMilliseconds()).padStart(3, "0");

    const timestampWithOffset = `${year}-${month}-${day}T${hours}:${minutes}:${seconds}.${milliseconds}+08:00`;

    const traceEvent = {
      id: eventId,
      type: eventTypes.TRACE_CREATE,
      timestamp: timestampWithOffset,
      metadata: {
        manualTracing: true, // æ ‡è®°ä¸ºæ‰‹åŠ¨åŸ‹ç‚¹
        provider: "PowerRAG",
        createdAt: timestampWithOffset,
      },
      body: {
        id: traceId,
        timestamp: timestampWithOffset,
        name: name,
        input: input,
        output: output,
        environment: environment,
        startTime: startTime.toISOString(),
        endTime: endTime.toISOString(),
        metadata: {
          ...metadata,
          manualTracing: true, // æ ‡è®°ä¸ºæ‰‹åŠ¨åŸ‹ç‚¹
          provider: "PowerRAG",
          createdAt: timestampWithOffset,
          duration: endTime.getTime() - startTime.getTime(), // è®¡ç®—è€—æ—¶ï¼ˆæ¯«ç§’ï¼‰
          // ç¡®ä¿æ‰€æœ‰Dateå¯¹è±¡éƒ½è½¬æ¢ä¸ºISOå­—ç¬¦ä¸²
          startTime: startTime.toISOString(),
          endTime: endTime.toISOString(),
        },
        public: false, // é»˜è®¤ç§æœ‰
        tags: ["powerrag", "manual-tracing"], // æ·»åŠ æ ‡ç­¾ä»¥ä¾¿è¯†åˆ«
      },
    };

    // åˆ›å»ºè®¤è¯æ£€æŸ¥å¯¹è±¡
    const authCheck = {
      validKey: true as const,
      scope: {
        projectId:
          projectId || env.LANGFUSE_PROJECT_ID || "powerrag-default-project", // ç¡®ä¿projectIdæœ‰å€¼ï¼Œä¼˜å…ˆçº§ï¼šå‚æ•° > ç¯å¢ƒå˜é‡ > é»˜è®¤å€¼
        accessLevel: "project" as const,
        // å¯¹äºå†…éƒ¨ä½¿ç”¨ï¼Œå…¶ä»–å­—æ®µæ˜¯å¯é€‰çš„
      },
    };

    let result;
    try {
      result = await processEventBatch([traceEvent], authCheck, {
        isLangfuseInternal: false,
      });
    } catch (error) {
      logger.error("processEventBatchè°ƒç”¨å¼‚å¸¸", {
        error: error instanceof Error ? error.message : String(error),
        errorStack: error instanceof Error ? error.stack : undefined,
        errorName: error instanceof Error ? error.name : undefined,
        errorConstructor: error?.constructor?.name,
        errorPrototype: Object.getPrototypeOf(error)?.constructor?.name,
        traceId,
        projectId,
        eventId,
        context: {
          traceEventType: traceEvent.type,
          traceEventBodyKeys: Object.keys(traceEvent.body),
          authCheckValidKey: authCheck.validKey,
          authCheckScopeKeys: Object.keys(authCheck.scope),
          isLangfuseInternal: false,
        },
        completion:
          "processEventBatchè°ƒç”¨è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸ï¼Œè®°å½•è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯å’Œä¸Šä¸‹æ–‡",
      });
      throw error;
    }

    if (result.errors.length > 0) {
      const error = result.errors[0];
      logger.error("æ‰‹åŠ¨traceåˆ›å»ºå¤±è´¥ - processEventBatché”™è¯¯", {
        error: error.error || error.message,
        status: error.status,
        traceId,
        projectId,
        eventId,
      });
      throw new Error(
        `Failed to create trace: ${error.error || error.message} (Status: ${error.status})`,
      );
    }

    logger.info("æ‰‹åŠ¨traceåˆ›å»ºæˆåŠŸ", {
      traceId,
      projectId,
      eventId,
      successes: result.successes.length,
    });
  } catch (error) {
    logger.error("æ‰‹åŠ¨traceåˆ›å»ºå¤±è´¥", {
      error: error instanceof Error ? error.message : String(error),
      traceId,
      projectId,
      environment,
      name,
    });
    throw error;
  }
}
